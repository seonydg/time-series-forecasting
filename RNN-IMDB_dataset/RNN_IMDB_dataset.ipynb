{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.legacy.data.Field(lower=True,  fix_length=200, batch_first=True)\n",
    "LABEL = torchtext.legacy.data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train/val/test data 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy.', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life,', 'such', 'as', '\"teachers\".', 'my', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'bromwell', \"high's\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"teachers\".', 'the', 'scramble', 'to', 'survive', 'financially,', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', \"teachers'\", 'pomp,', 'the', 'pettiness', 'of', 'the', 'whole', 'situation,', 'all', 'remind', 'me', 'of', 'the', 'schools', 'i', 'knew', 'and', 'their', 'students.', 'when', 'i', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school,', 'i', 'immediately', 'recalled', '.........', 'at', '..........', 'high.', 'a', 'classic', 'line:', 'inspector:', \"i'm\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers.', 'student:', 'welcome', 'to', 'bromwell', 'high.', 'i', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'bromwell', 'high', 'is', 'far', 'fetched.', 'what', 'a', 'pity', 'that', 'it', \"isn't!\"], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exam in train_data.examples:\n",
    "    text = [x.lower() for x in vars(exam)['text']]\n",
    "    text = [x.replace('<br', '') for x in text]\n",
    "    text = [''.join(c for c in s if c not in string.punctuation) for s in text]\n",
    "    text = [s for s in text if s]\n",
    "    vars(exam)['text'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_data.split(random_state=random.seed(0), split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 20000\n",
      "Number of val examples: 5000\n",
      "Number of test examples: 25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of train examples: {len(train_data)}')\n",
    "print(f'Number of val examples: {len(val_data)}')\n",
    "print(f'Number of test examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단어 집합 만들기 : build_vocab\n",
    "    - max_size : 단어 집합의 크기로 단어 집합에 포함되는 어휘 수\n",
    "    - min_freq : 특정 단어의 최소 등장 횟수\n",
    "    - vector : 임베딩 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 10002\n",
      "Unique tokens in LABEL vocabulary: 3\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data, max_size=10000, min_freq=10, vectors=None)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f'Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}')\n",
    "print(f'Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x00000166153E2A90>>, {'<unk>': 0, 'pos': 1, 'neg': 2})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader = torchtext.legacy.data.BucketIterator.splits((train_data, val_data, test_data), batch_size=BATCH_SIZE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2 # 긍정/부정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import BasicRNN\n",
    "from utils import train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicRNN(n_layers=1, hidden_dim=256, n_vocab=vocab_size, embed_dim=128, n_classes=n_classes, dropout_p=0.5)\n",
    "model.to(DEVICE)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicRNN(\n",
      "  (embed): Embedding(10002, 128)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (rnn): RNN(128, 256, batch_first=True)\n",
      "  (out): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/20000(0.0%)] \tLoss: 0.683027\n",
      "Train Epoch: 1 [5000/20000(25.0%)] \tLoss: 0.694591\n",
      "Train Epoch: 1 [10000/20000(50.0%)] \tLoss: 0.681756\n",
      "Train Epoch: 1 [15000/20000(75.0%)] \tLoss: 0.700426\n",
      "[EPOCH: 1], Val Loss: 0.6894723617553711 | Val Accuracy: 0.5162000060081482\n",
      "Train Epoch: 2 [0/20000(0.0%)] \tLoss: 0.662277\n",
      "Train Epoch: 2 [5000/20000(25.0%)] \tLoss: 0.683297\n",
      "Train Epoch: 2 [10000/20000(50.0%)] \tLoss: 0.689828\n",
      "Train Epoch: 2 [15000/20000(75.0%)] \tLoss: 0.666543\n",
      "[EPOCH: 2], Val Loss: 0.6954123641967773 | Val Accuracy: 0.5013999938964844\n",
      "Train Epoch: 3 [0/20000(0.0%)] \tLoss: 0.684097\n",
      "Train Epoch: 3 [5000/20000(25.0%)] \tLoss: 0.693774\n",
      "Train Epoch: 3 [10000/20000(50.0%)] \tLoss: 0.694919\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\GitHub\\time-series-forecasting\\RNN-IMDB_dataset\\RNN_IMDB_dataset.ipynb Cell 20\u001b[0m line \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m EPOCH \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCH\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     train(model\u001b[39m=\u001b[39;49mmodel, optimizer\u001b[39m=\u001b[39;49moptimizer, train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader, device\u001b[39m=\u001b[39;49mDEVICE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     val_loss, val_accuracy \u001b[39m=\u001b[39m evaluate(model\u001b[39m=\u001b[39mmodel, val_dataloader\u001b[39m=\u001b[39mval_dataloader, device\u001b[39m=\u001b[39mDEVICE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[EPOCH: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m], Val Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m}\u001b[39;00m\u001b[39m | Val Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mval_accuracy\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32md:\\GitHub\\time-series-forecasting\\RNN-IMDB_dataset\\RNN_IMDB_dataset.ipynb Cell 20\u001b[0m line \u001b[0;36mtrain\u001b[1;34m(model, optimizer, train_dataloader, device)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m logit \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcross_entropy(logit, y)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/GitHub/time-series-forecasting/RNN-IMDB_dataset/RNN_IMDB_dataset.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    247\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    248\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    249\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    254\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 255\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m--> 147\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[0;32m    148\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    149\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "LR = 0.001\n",
    "EPOCH = 5\n",
    "\n",
    "for e in range(1, EPOCH+1):\n",
    "    train(model=model, optimizer=optimizer, train_dataloader=train_dataloader, device=DEVICE)\n",
    "    val_loss, val_accuracy = evaluate(model=model, val_dataloader=val_dataloader, device=DEVICE)\n",
    "\n",
    "    print(f'[EPOCH: {e}], Val Loss: {val_loss} | Val Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.697592 | Test Acc: 0.502680\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model=model, val_dataloader=test_dataloader, device=DEVICE)\n",
    "print(f'Test Loss: {test_loss:.6f} | Test Acc: {test_acc:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

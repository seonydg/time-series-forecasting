{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253 entries, 0 to 252\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Date       253 non-null    object \n",
      " 1   Open       253 non-null    float64\n",
      " 2   High       253 non-null    float64\n",
      " 3   Low        253 non-null    float64\n",
      " 4   Close      253 non-null    float64\n",
      " 5   Adj Close  253 non-null    float64\n",
      " 6   Volume     253 non-null    int64  \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 14.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/SBUX.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-11</td>\n",
       "      <td>86.260002</td>\n",
       "      <td>86.870003</td>\n",
       "      <td>85.849998</td>\n",
       "      <td>86.589996</td>\n",
       "      <td>84.145752</td>\n",
       "      <td>4921900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.889999</td>\n",
       "      <td>87.540001</td>\n",
       "      <td>88.209999</td>\n",
       "      <td>85.720032</td>\n",
       "      <td>10282100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>88.019997</td>\n",
       "      <td>88.790001</td>\n",
       "      <td>87.580002</td>\n",
       "      <td>88.669998</td>\n",
       "      <td>86.167046</td>\n",
       "      <td>6714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>89.139999</td>\n",
       "      <td>89.300003</td>\n",
       "      <td>88.430000</td>\n",
       "      <td>88.779999</td>\n",
       "      <td>86.273941</td>\n",
       "      <td>6705600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>88.870003</td>\n",
       "      <td>88.970001</td>\n",
       "      <td>87.470001</td>\n",
       "      <td>88.129997</td>\n",
       "      <td>85.642288</td>\n",
       "      <td>7296900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close    Volume\n",
       "0  2019-12-11  86.260002  86.870003  85.849998  86.589996  84.145752   4921900\n",
       "1  2019-12-12  88.000000  88.889999  87.540001  88.209999  85.720032  10282100\n",
       "2  2019-12-13  88.019997  88.790001  87.580002  88.669998  86.167046   6714100\n",
       "3  2019-12-16  89.139999  89.300003  88.430000  88.779999  86.273941   6705600\n",
       "4  2019-12-17  88.870003  88.970001  87.470001  88.129997  85.642288   7296900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-11</th>\n",
       "      <td>86.260002</td>\n",
       "      <td>86.870003</td>\n",
       "      <td>85.849998</td>\n",
       "      <td>86.589996</td>\n",
       "      <td>84.145752</td>\n",
       "      <td>4921900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>88.889999</td>\n",
       "      <td>87.540001</td>\n",
       "      <td>88.209999</td>\n",
       "      <td>85.720032</td>\n",
       "      <td>10282100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13</th>\n",
       "      <td>88.019997</td>\n",
       "      <td>88.790001</td>\n",
       "      <td>87.580002</td>\n",
       "      <td>88.669998</td>\n",
       "      <td>86.167046</td>\n",
       "      <td>6714100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16</th>\n",
       "      <td>89.139999</td>\n",
       "      <td>89.300003</td>\n",
       "      <td>88.430000</td>\n",
       "      <td>88.779999</td>\n",
       "      <td>86.273941</td>\n",
       "      <td>6705600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>88.870003</td>\n",
       "      <td>88.970001</td>\n",
       "      <td>87.470001</td>\n",
       "      <td>88.129997</td>\n",
       "      <td>85.642288</td>\n",
       "      <td>7296900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close      Volume\n",
       "Date                                                                         \n",
       "2019-12-11  86.260002  86.870003  85.849998  86.589996  84.145752   4921900.0\n",
       "2019-12-12  88.000000  88.889999  87.540001  88.209999  85.720032  10282100.0\n",
       "2019-12-13  88.019997  88.790001  87.580002  88.669998  86.167046   6714100.0\n",
       "2019-12-16  89.139999  89.300003  88.430000  88.779999  86.273941   6705600.0\n",
       "2019-12-17  88.870003  88.970001  87.470001  88.129997  85.642288   7296900.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data.set_index('Date', inplace=True)\n",
    "data['Volume'] = data['Volume'].astype(float)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Volume', axis=1)\n",
    "Y = data[['Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 5), (200, 1), (53, 5), (53, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_ss = ss.fit_transform(X)\n",
    "Y_ms = ms.fit_transform(Y)\n",
    "\n",
    "train_x = X_ss[:200, :]\n",
    "test_x = X_ss[200:, :]\n",
    "train_y = Y_ms[:200, :]\n",
    "test_y = Y_ms[200:, :]\n",
    "\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 1, 5]),\n",
       " torch.Size([200, 1]),\n",
       " torch.Size([53, 1, 5]),\n",
       " torch.Size([53, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor_x = Variable(torch.Tensor(train_x))\n",
    "test_tensor_x = Variable(torch.Tensor(test_x))\n",
    "train_tensor_y = Variable(torch.Tensor(train_y))\n",
    "test_tensor_y = Variable(torch.Tensor(test_y))\n",
    "\n",
    "train_x_f = torch.reshape(train_tensor_x, (train_tensor_x.shape[0], 1, train_tensor_x.shape[1]))\n",
    "test_x_f = torch.reshape(test_tensor_x, (test_tensor_x.shape[0], 1, test_tensor_x.shape[1]))\n",
    "\n",
    "train_x_f.shape, train_tensor_y.shape, test_x_f.shape, test_tensor_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.seq_length =seq_length\n",
    "\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc_1 = nn.Linear(hidden_size, 128)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        output, (hn) = self.gru(x, (h_0))\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(\n",
       "  (gru): GRU(5, 2, batch_first=True)\n",
       "  (fc_1): Linear(in_features=2, out_features=128, bias=True)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10000\n",
    "lr = 0.0001\n",
    "input_size = 5\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "num_classes = 1\n",
    "\n",
    "model = GRU(num_classes=num_classes, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, seq_length=train_x_f.shape[1])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10000 Loss : 0.23557478189468384\n",
      "Epoch: 100/10000 Loss : 0.09250225126743317\n",
      "Epoch: 200/10000 Loss : 0.047734297811985016\n",
      "Epoch: 300/10000 Loss : 0.03902890160679817\n",
      "Epoch: 400/10000 Loss : 0.03751537203788757\n",
      "Epoch: 500/10000 Loss : 0.036522869020700455\n",
      "Epoch: 600/10000 Loss : 0.035416003316640854\n",
      "Epoch: 700/10000 Loss : 0.03422226384282112\n",
      "Epoch: 800/10000 Loss : 0.03312848508358002\n",
      "Epoch: 900/10000 Loss : 0.03215838596224785\n",
      "Epoch: 1000/10000 Loss : 0.03130976855754852\n",
      "Epoch: 1100/10000 Loss : 0.030466163530945778\n",
      "Epoch: 1200/10000 Loss : 0.029540080577135086\n",
      "Epoch: 1300/10000 Loss : 0.02846020646393299\n",
      "Epoch: 1400/10000 Loss : 0.02728709764778614\n",
      "Epoch: 1500/10000 Loss : 0.02600707858800888\n",
      "Epoch: 1600/10000 Loss : 0.024691088125109673\n",
      "Epoch: 1700/10000 Loss : 0.023339739069342613\n",
      "Epoch: 1800/10000 Loss : 0.02193283475935459\n",
      "Epoch: 1900/10000 Loss : 0.020478643476963043\n",
      "Epoch: 2000/10000 Loss : 0.01902596652507782\n",
      "Epoch: 2100/10000 Loss : 0.017619602382183075\n",
      "Epoch: 2200/10000 Loss : 0.016303755342960358\n",
      "Epoch: 2300/10000 Loss : 0.014957547187805176\n",
      "Epoch: 2400/10000 Loss : 0.013839810155332088\n",
      "Epoch: 2500/10000 Loss : 0.013011403381824493\n",
      "Epoch: 2600/10000 Loss : 0.012421183288097382\n",
      "Epoch: 2700/10000 Loss : 0.012016401626169682\n",
      "Epoch: 2800/10000 Loss : 0.011706617660820484\n",
      "Epoch: 2900/10000 Loss : 0.011510413140058517\n",
      "Epoch: 3000/10000 Loss : 0.011375890113413334\n",
      "Epoch: 3100/10000 Loss : 0.011273959651589394\n",
      "Epoch: 3200/10000 Loss : 0.011199766770005226\n",
      "Epoch: 3300/10000 Loss : 0.011145703494548798\n",
      "Epoch: 3400/10000 Loss : 0.011107471771538258\n",
      "Epoch: 3500/10000 Loss : 0.011071469634771347\n",
      "Epoch: 3600/10000 Loss : 0.011003529652953148\n",
      "Epoch: 3700/10000 Loss : 0.010962795466184616\n",
      "Epoch: 3800/10000 Loss : 0.01093151792883873\n",
      "Epoch: 3900/10000 Loss : 0.010903683491051197\n",
      "Epoch: 4000/10000 Loss : 0.010869917459785938\n",
      "Epoch: 4100/10000 Loss : 0.010834161192178726\n",
      "Epoch: 4200/10000 Loss : 0.010794770903885365\n",
      "Epoch: 4300/10000 Loss : 0.010757779702544212\n",
      "Epoch: 4400/10000 Loss : 0.010724007152020931\n",
      "Epoch: 4500/10000 Loss : 0.010691272094845772\n",
      "Epoch: 4600/10000 Loss : 0.010663297958672047\n",
      "Epoch: 4700/10000 Loss : 0.010640298947691917\n",
      "Epoch: 4800/10000 Loss : 0.010619359090924263\n",
      "Epoch: 4900/10000 Loss : 0.010599145665764809\n",
      "Epoch: 5000/10000 Loss : 0.010579957626760006\n",
      "Epoch: 5100/10000 Loss : 0.01056146901100874\n",
      "Epoch: 5200/10000 Loss : 0.010543690994381905\n",
      "Epoch: 5300/10000 Loss : 0.010526333004236221\n",
      "Epoch: 5400/10000 Loss : 0.010509362444281578\n",
      "Epoch: 5500/10000 Loss : 0.010492660105228424\n",
      "Epoch: 5600/10000 Loss : 0.0104769766330719\n",
      "Epoch: 5700/10000 Loss : 0.010462585836648941\n",
      "Epoch: 5800/10000 Loss : 0.010448588989675045\n",
      "Epoch: 5900/10000 Loss : 0.010435151867568493\n",
      "Epoch: 6000/10000 Loss : 0.01042188610881567\n",
      "Epoch: 6100/10000 Loss : 0.010409160517156124\n",
      "Epoch: 6200/10000 Loss : 0.010396615602076054\n",
      "Epoch: 6300/10000 Loss : 0.010384418070316315\n",
      "Epoch: 6400/10000 Loss : 0.010372132994234562\n",
      "Epoch: 6500/10000 Loss : 0.010340451262891293\n",
      "Epoch: 6600/10000 Loss : 0.010293726809322834\n",
      "Epoch: 6700/10000 Loss : 0.01025346852838993\n",
      "Epoch: 6800/10000 Loss : 0.01021585427224636\n",
      "Epoch: 6900/10000 Loss : 0.010182426311075687\n",
      "Epoch: 7000/10000 Loss : 0.010145002976059914\n",
      "Epoch: 7100/10000 Loss : 0.010112627409398556\n",
      "Epoch: 7200/10000 Loss : 0.010085995309054852\n",
      "Epoch: 7300/10000 Loss : 0.010063000954687595\n",
      "Epoch: 7400/10000 Loss : 0.010036757215857506\n",
      "Epoch: 7500/10000 Loss : 0.009999940171837807\n",
      "Epoch: 7600/10000 Loss : 0.009982399642467499\n",
      "Epoch: 7700/10000 Loss : 0.009966394864022732\n",
      "Epoch: 7800/10000 Loss : 0.009951523505151272\n",
      "Epoch: 7900/10000 Loss : 0.00993724912405014\n",
      "Epoch: 8000/10000 Loss : 0.009923957288265228\n",
      "Epoch: 8100/10000 Loss : 0.009911274537444115\n",
      "Epoch: 8200/10000 Loss : 0.009900487959384918\n",
      "Epoch: 8300/10000 Loss : 0.009890362620353699\n",
      "Epoch: 8400/10000 Loss : 0.009880444034934044\n",
      "Epoch: 8500/10000 Loss : 0.009870834648609161\n",
      "Epoch: 8600/10000 Loss : 0.009861836209893227\n",
      "Epoch: 8700/10000 Loss : 0.009853133000433445\n",
      "Epoch: 8800/10000 Loss : 0.00984465517103672\n",
      "Epoch: 8900/10000 Loss : 0.009836513549089432\n",
      "Epoch: 9000/10000 Loss : 0.009828392416238785\n",
      "Epoch: 9100/10000 Loss : 0.009820821695029736\n",
      "Epoch: 9200/10000 Loss : 0.009813584387302399\n",
      "Epoch: 9300/10000 Loss : 0.00980668980628252\n",
      "Epoch: 9400/10000 Loss : 0.009800097905099392\n",
      "Epoch: 9500/10000 Loss : 0.009793446399271488\n",
      "Epoch: 9600/10000 Loss : 0.009787226095795631\n",
      "Epoch: 9700/10000 Loss : 0.009781170636415482\n",
      "Epoch: 9800/10000 Loss : 0.009775245562195778\n",
      "Epoch: 9900/10000 Loss : 0.009769433178007603\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    outputs = model.forward(train_x_f)\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(outputs, train_tensor_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch}/{num_epochs} Loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
